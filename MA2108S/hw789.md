---
title: MA2108S Homework sets 7, 8, 9, 10
author: Qi Ji [A0167793L]
date: 20th April 2019
...

\let\subseteq\subset
\let\epsilon\varepsilon
\let\setminus\smallsetminus
\newcommand{\set}[1]{{\left\{ #1 \right\}}}
\newcommand{\abs}[1]{\left\lvert #1 \right\rvert}
\newcommand{\qed}{\hfill$\square$}
\newcommand{\tagQED}{\tag*{$\square$}}
\newcommand{\R}{\mathbb{R}}
\renewcommand{\C}{\mathbb{C}}
\newcommand{\N}{\mathbb{N}}

# Homework 7

## Rudin Chapter 3 Q6

(a) The partial sum of first \(N\) terms evaluate to \(\sqrt{N+1} - 1\) which obviously diverges.

(b) For each \(n\in\N\) we have
\begin{align*}
a_n &= \frac{\sqrt{n+1}-\sqrt{n}}n \\
&- \frac{1}{n(\sqrt{n+1}+\sqrt{n})}
\end{align*}
and since \(n(\sqrt{n+1}+\sqrt{n}) > n\sqrt{n}\), \(a_n < 1/n^{3/2}\).
Because \(\sum \frac{1}{n^{3/2}}\) converges by comparison test \(\sum a_n\) converges.

(c) \(\sqrt[n]{\abs{a_n}} = \sqrt[n]{n} - 1\). From Theorem 3.20 we have
\(\lim_{n\to\infty} \sqrt[n]{\abs{a_n}} = 1 - 1 = 0\) so by root test \(\sum a_n\) converges.

(d) Whenever \(\abs{z} > 1\),
\begin{align*}
\lim_{n\to\infty}\abs{\frac{a_{n+1}}{a_n}}
&= \lim_{n\to\infty}\abs{\frac{1 + z^n}{1 + z^{n+1}}} \\
&= \lim_{n\to\infty}\frac{\abs{\frac{1}{z^n} + 1}}{\abs{\frac1{z^n} + z}} \\
&< \frac1{\abs{z}} < 1
\end{align*}
so \(\sum a_n\) converges by ratio test.

    In the other case when \(\abs{z}\geq 1\) then
\[ \abs{1 + z^n} \leq 1 + \abs{z}^n \leq 2 \]
so for all \(n\in\N\), \(\abs{a_n} \geq \frac12\) and \(\sum a_n\) diverges.


## Rudin Chapter 3 Q9

(a) \(\sum n^3 z^n\)
\begin{align*}
\lim_{n\to\infty} \abs{\frac{(n+1)^3z^{n+1}}{n^3z^3}}
&= \abs{z} \lim_{n\to\infty} \abs{\frac{n^3 + O(n^2)}{n^3}} \\
&= \abs{z}
\end{align*}
so \(R=1\).

(b) \(\sum \frac{2^n}{n!}z^n\)
\begin{align*}
\lim_{n\to\infty} \abs{\cfrac{\frac{2^{n+1}}{(n+1)!}}{\frac{2^n}{n!}}}
&= \lim_{n\to\infty} \abs{\frac{2}{n+1}} = 0
\end{align*}
so \(R = \infty\), this series converges everywhere in \(\mathbb{C}\).

(c) \(\sum \frac{2^n}{n^2}z^n\)
\begin{align*}
\lim_{n\to\infty} \abs{\cfrac{\frac{2^{n+1}}{(n+1)^2}}{\frac{2^n}{n^2}}}
&= \lim_{n\to\infty} \abs{\frac{2n^2}{(n+1)^2}} = 2
\end{align*}
so \(R = \frac12\)

(d) \(\sum \frac{n^3}{3^n}z^n\)
\begin{align*}
\lim_{n\to\infty} \abs{\cfrac{\frac{3^{n+1}}{(n+1)^3}}{\frac{3^n}{n^3}}}
&= \lim_{n\to\infty} \abs{\frac{3n^3}{(n+1)^3}} = 3
\end{align*}
so \(R = \frac13\)

## Rudin Chapter 3 Q10

Suppose for a contradiction the power series of almost all non-zero integer coefficients \(\sum a_n z^n\)
converges but for some \(z\) with \(\abs{z}>1\).
By convergence it is necessary that \(\lim_{n\to\infty} \abs{a_n z^n} = 0\), but
by hypothesis for each \(N\in\N\) there exists \(n>N\) with integer coefficient \(a_n \ne 0\), and because
\(\abs{z}>1\), \(\abs{a_nz^n} >1\), which contradicts the claim that limit goes to \(0\).

## Rudin Chapter 3 Q13

To simplify the question we can assume terms from both series are \(\geq 0\), so given two absolutely
convergent series of nonnegative terms, denote
\[ A_n = \sum_{i=1}^n a_i \to A,\quad B_n = \sum_{j=1}^n b_j \to B \]
we just have to show \( C_n := \sum_{i=0}^n \sum_{j=0}^i a_j b_{i-j} \)
is a bounded sequence of partial sums.

For each \(i\in\N\) denote
\begin{align*}
c_i &= \sum_{j=0}^i a_j b_{i-j} \\
&= \sum_{j=0}^{i-1} A_j(b_{i-j} - b_{i-(j+1)}) + A_ib_0 - A_{-1}b_i\\
&= \sum_{j=0}^i A_j (b_{i-j} - b_{i-j-1})
\end{align*}
where we set \(A_{-1} = b_{-1} = 0\) to simplify our term.
Now for each \(n\in\N\)
\begin{align*}
C_n &= \sum_{i=0}^n c_i \\
&= \sum_{i=0}^n \sum_{j=0}^i A_j (b_{i-j} - b_{i-j-1}) \\
&= \sum_{j=0}^n \sum_{i=j}^n A_j (b_{i-j} - b_{i-j-1}) \\
&= \sum_{j=0}^n A_j \sum_{i=j}^n (b_{i-j} - b_{i-j-1}) \\
&= \sum_{j=0}^n A_j b_{n-j} \\
&\leq \sum_{j=0}^n A b_{n-j} \\
&= A \sum_{k=0}^n b_{k} = A B_n \leq AB \\
\end{align*}
so the partial sums are bounded.

# Homework 8

## Rudin Chapter 3 Q18

Choose \(x_1>\sqrt[p]{\alpha}\),
the sequence decreases monotonically with limit \(\sqrt[p]{\alpha}\).

Suppose \(x_n \geq \sqrt[p]{\alpha}\) we show \(x_{n+1} \geq \sqrt[p]{\alpha}\) too.
By AM-GM inequality
\begin{align*}
x_{n+1} &= \frac{p-1}{p}x_n + \frac{\alpha}{p} x_n^{-p+1} \\
&= \frac{\overbrace{x_n + x_n + \dots + x_n}^{p-1\text{ copies}} + \alpha\cdot x_n^{-p+1}}p \\
&\geq \sqrt[p]{x_n^{p-1}\cdot\alpha\cdot x_n^{-p+1}} \\
&= \sqrt[p]{\alpha}
\end{align*}
so by induction the sequence is bounded below by \(\sqrt[p]{\alpha}\).

Suppose \(x_n\geq \sqrt[p]{\alpha}\) we show \(x_{n+1} \leq x_n\).
\begin{align*}
x_{n+1} &= \frac{p-1}{p}x_n + \frac{\alpha}{p} x_n^{-p+1} \\
&= x_n \frac1p \left(p-1 + \frac{\alpha}{x_n^p} \right)
\end{align*}
Since \(x_n\geq \sqrt[p]{\alpha}\) by assumption we observe that
\begin{align*}
x_n^p &\geq \alpha \\
\frac{\alpha}{x_n^p} &\leq 1\\
p - 1 + \frac{\alpha}{x_n^p} &\leq p \\
\frac1p\left(p - 1 + \frac{\alpha}{x_n^p}\right) &\leq 1
\end{align*}
where equality holds if and only if it holds in our assumption.
This means \(x_{n+1} \leq x_n\) where equality holds iff \(x_n = \sqrt[p]{\alpha}\).

<!---
* \(\epsilon_{n+1} = \frac{\epsilon_n^2}{2 x^n} < \frac{\epsilon_n^2}{2\sqrt[p]{\alpha}}\)
-->

## Q1

> Suppose \(\sum_{n=1}^\infty a_n\) converges where each \(a_n\geq 0\).
> Determine whether \(\sum_n \sqrt{a_n a_{n+1}}\) also converges.

As \(\sum_{n=1}^\infty a_n\) converges, we can drop the first term so \(\sum_{n=1}^\infty a_{n+1}\) still converges.
Then we see that \[\sum_{n=1}^\infty \frac{a_n + a_{n+1}}2 \] converges.
Then by AM-GM inequality
\[ \sqrt{a_na_{n+1}} \leq \frac{a_n + a_{n+1}}2\]
and by comparison test \(\sum_n \sqrt{a_n a_{n+1}}\) converges.

## Q2

> Fix \(\alpha \in (0,1)\),
> show that \(\sum_{n=1}^\infty \frac{\cos nx}{n^\alpha}\) converges for all \(x\) except multiples of \(2\pi\).

In the case that \(x\) is an integer multiple of \(2\pi\), the series becomes
\(\sum_{n=1}^\infty \frac1{n^\alpha}\) which diverges because \(\alpha \leq 1\).

In the other case assume \(x \ne 2\pi k\) for all \(k\in\mathbb{Z}\).
We show that
\[ \sum_{n=1}^\infty \frac{e^{inx}}{n^\alpha} \]
converges.

First see that \(\frac1{n^\alpha}\) is a decreasing sequence of real numbers with limit \(0\).
Next we set \(b_n := e^{inx}\) and \(b_N := \sum_{n=1}^N b_n\),
Now we note that for each \(n\in\N\), as \(x\) is not a multiple of \(2\pi\), we have the finite geometric sum
\[ \abs{B_n} = \abs{ e^{ix}\left(\frac{1-e^{inx}}{1-e^{ix}}\right) } \leq \frac{2}{\abs{1-e^{ix}}} \]
note that \(x\) is a fixed constant so the partial sums are bounded.
Applying Dirichlet's test (3.42) the series converges.

## Q3

### Part (a)

We can re-express our terms for readability as
\[ a_n = \begin{cases}
    -\frac2{n^2} &\text{if \(n\) is odd}\\
    \frac2{n} &\text{if \(n\) is even}
\end{cases} \]
to show \(\sum_{n=1}^\infty a_n\) diverges consider the series of every 2 terms grouped together,
\[ \sum_{n=1}^\infty b_n \text{ where } b_n := -\frac2{n^2} + \frac2{(n+1)} \]
for all \(n\geq 3\) it holds that
\begin{align*}
n^2 &> 2(n+1) \\
\frac1{n^2} &< \frac{1}{2(n+1)} \\
\frac1{n+1} - \frac1{n^2} &> \frac{1}{2(n+1)}
b_n > \frac1{n+1}
\end{align*}
then by comparison test with harmonic series \(\sum b_n\) diverges.

### Part (b)

Given \(a_n = \frac1{(\log n)^{\log n}} \) we want to find convergence of
\(\sum_{n=2}^\infty a_n\).
By theorem of Cauchy it converges iff this series converges
\[\sum_{k=1}^\infty 2^ka_k = \sum_{n=1}^\infty 2^k \frac1{(\log 2^k)^{\log 2^k}}. \]
Define each summand in RHS as \(c_n\) and simplify
\begin{align*}
c_n &= \frac{2^n}{(n\log 2)^{n\log 2}} \\
&= \frac1{n^{n\log 2}}\cdot\left( \frac{2}{(\log 2)^{\log 2}} \right)^n
\end{align*}
To see that \(\sum_{n=1}^\infty c_n\) converges we first note that
\(r :=\frac{2}{(\log 2)^{\log 2}} < 1\) so \(\sum_{n=1}^\infty r^n\) is a convergent geometric series.
Next we see that \(\sum_{i=1}^\infty \frac1{n^{n\log 2}}\) also converges by ratio test, as
\begin{align*}
\lim_{n\to\infty} \abs{\frac{n^{n\log 2}}{(n+1)^{(n+1)\log 2}}}
&= \lim_{n\to\infty} \abs{\frac{n^{n}}{(n+1)^{(n+1)}}}^{\log 2} \\
&= \lim_{n\to\infty} \abs{ \left(\frac{n}{n+1}\right)^n \frac1{n+1} }^{\log 2} \\
&= \lim_{n\to\infty} \abs{ \frac{1}{\left(1+\frac1n\right)^n} \frac1{n+1} }^{\log 2} \\
&= 0
\end{align*}
Therefore the original series was convergent.

### Part (c)

We can see that whenever \(\abs{\alpha} \geq 1\),
\(n\mapsto \sqrt[n]{\abs{\alpha}}\) is decreasing, so
\(\abs{\frac{\sqrt[n]{\abs{\alpha}}}n}\) is decreasing so the conditions of 3.43 is satisfied and the series converges.

When \(0 < \abs{\alpha} < 1\), we find \(N\) such that for any \(n>N\), \(\sqrt[n]{\alpha} > \frac12\).
Now if we examine the tail of the series each term is greater than \(b_n := \frac{1}{2(N+n)}\).
But \(\sum b_n\) is the tail sum of (half of) harmonic series, which diverges.
So by comparison test the original series diverges.

Convergence is obvious for \(\alpha=0\).

# Homework 9

## Rudin Chapter 4 Q2

Let \(y\in f(\overline{E})\), want to show \(y\in\overline{f(E)}\).
Find \(x\in\overline{E}\) such that \(f(x) = y\),
then there exists a sequence \(x_1,x_2,\dots \in E\)
such that \(x_n \to x\).
Note that for each \(x_n\in E\), we have \(f(x_n) \in f(E)\), then because \(f\) is continuous
\[y = f(x) = f\left(\lim_{n\to\infty} x_n\right) = \lim_{n\to\infty} f(x_n)\]
which shows \(y\in\overline{f(E)}\).

## Rudin Chapter 4 Q3

Note that \(Z(f) := \set{x\in X:f(x)=0} = f^{-1}(\set{0})\) the pre-image of \(\set{0}\).
Since \(\set{0}\) is closed in \(\R\) and \(f\) is continuous it follows that \(Z(f)\) is closed.

## Rudin Chapter 4 Q16

For each integer \(n\in\mathbb{Z}\), \([x]\) and \((x)\) are continuous on the interval \((n,n+1)\),
which is easier to see by sketching the graph.

To see that \((x)\) is discontinuous at all integer points, consider \(\epsilon=\frac12\),
then for any \(\delta>0\) there is an \(x \in (n-\delta,n+\delta)\) such that \((x) \geq \frac12\)
(concretely maybe choose \(x=\max(n-\frac1m, n-\frac12)\) where \(\frac1m < \delta\)).

To see that case of \([x]\) is similar we see that the difference between \([x]\) and \((x)\) is a continuous function since it was defined that \((x) = x - [x]\).

## Rudin Chapter 4 Q18

For any \(x\in\R\), we show that \(\lim_{y\to x} f(y) = 0\).

Given \(\epsilon>0\) we find the smallest \(N\in\N\) such that
\[ \frac1{N-1}\geq \epsilon > \frac1N. \]

Next to each \(n=1,2,\dots,N\), let \(z_n\) such that
\[\frac{z_n}n \leq x < \frac{z_n+1}n.\]
Then define 
\[ \delta_n := \begin{cases}
\min(x-\frac{z_n}n,\frac{z_n+1}n - x) &\text{if } x\ne \frac{z_n}n; \\
\frac1n &\text{otherwise}.
\end{cases} \]

Let \(\delta=\min(\delta_1,\dots,\delta_n\) and for any \(y\in (x-\delta,x+\delta)\setminus\set{x}\),
if \(y\) is irrational \(f(y)=0<\epsilon\),
if \(y\) is rational then \(y=\frac{a}b\) for some \(a,b\in\mathbb{Z}\) where \(b\ne 0,\gcd(a,b)=1\).
By our previous definitions it cannot be the case that \(b<N\) so \(0<f(y)<\frac1N < \epsilon\).

The claim \(\lim_{y\to x} f(y) = 0\) shows both claims.

# Homework 10

## Rudin Chapter 4 Q9

Fix metric spaces \(X,Y\) and function \(f: X\to Y\).
We begin by writing out definitions. \(f\) is uniformly continuous means
\[ \forall \epsilon>0 \exists \delta>0
\forall p,q\in X \left[
d_X(p,q)<\delta \implies d_Y(f(p),f(q)) < \epsilon
\right] \]

\newcommand{\diam}{\operatorname{diam}}

The question wants to rephrase it as
\[ \forall \epsilon>0 \exists \delta>0
\forall E\subset X\left[
\diam E < \delta \implies \diam f(E) < \epsilon
\right] \]
where \(\diam A := \sup_{x,y\in A} d(x,y)\).
Looking at the similarity of definitions we can just show logical equivalence of
\[
\forall p,q\in X \left[
d_X(p,q)<\delta \implies d_Y(f(p),f(q)) < \epsilon
\right] \tag{1} \]
and
\[
\forall E\subset X\left[
\diam E < \delta \implies \diam f(E) < \epsilon
\right] \tag{2} \]
fixing \(\epsilon\) and \(\delta\).

\((2)\implies (1)\)
: Assume \((2)\), consider \(\set{p,q}\subset X\).

\((1)\implies (2)\)
: Assume \((1)\), let \(E\subset X\) with \(\diam E = \sup_{x,y\in E} d_X(x,y) < \delta\).
Want to show \(\sup_{x,y\in E} d_Y(f(x),f(y)) < \epsilon\).
This holds because from assumption \(\diam E < \delta\), so for all \(x,y\in E\), \(d_X(x,y) < \delta\) and
by \((1)\), \(d_Y(f(x),f(y)) < \epsilon\).
Since the bound holds for all \(x,y\in E\) the bound is above the sup.

## Rudin Chapter 4 Q12

More precisely the statement says given \(f:X\to Y\) and \(g:Y\to Z\) uniformly continuous
\(g\circ f: X\to Z\) is also uniformly continuous.

Given \(\epsilon>0\) by uniform continuity of \(g\)
\[\exists \epsilon_1>0.~ \forall a,b\in Y.~ d_Y(a,b)<\epsilon_1 \implies d_Z(g(a),g(b)) <\epsilon.\]

Now as \(f\) is uniformly continuous,
\[\exists \delta>0.~ \forall c,d\in X.~ d_X(c,d)<\delta \implies d_Y(f(c),f(d))<\epsilon_1\]
and chaining the implications we get \(d_Z(g(f(c)),g(f(d))) < \epsilon\),
so \(g\circ f\) is uniformly continuous.


## Rudin Chapter 4 Q14

Define \(g(x) := f(x) - x\) which is continuous.
If \(g(0) = 0\) or \(g(1) = 0\) we are done.
In the other case \(g(0) = f(0) > 0\) and \(g(1) = f(1)-1 < 1-1 = 0\),
so by IVT there is \(c\in[0,1]\) with \(g(c) = 0 \implies f(c) = c\).

## Q (squeeze)

Given \(\epsilon>0\) there exist \(\delta_1,\delta_2\) such that
\[ 0<\abs{x-a}<\delta_1\implies \abs{f(x)-L}<\epsilon \]
\[ 0<\abs{x-a}<\delta_2\implies \abs{h(x)-L}<\epsilon \]
so choose \(\Delta = \min(\delta,\delta_1,\delta_2)\), then for all
\(x\in (x-\Delta,x+\Delta)\setminus\set{a}\),
we have
\[ f(x) - L \leq g(x) - L \leq h(x) - L\]
which means that
\[\abs{g(x)-L} \leq \max\left(
\abs{f(x)-L},\abs{h(x)-L}
\right) < \epsilon\]

To show that \(f(x)\) is continuous at \(0\) we first amend its definition
\[ f(x) := \begin{cases}
0 &\text{if } x = 0 \\
x\sin \frac1x &\text{otherwise}
\end{cases} \]
To use previous result observe that for all \(x\) near \(0\) we have
\[-\abs{x} \leq f(x) \leq \abs{x} \]
and because \(\lim_{x\to 0} \abs{x} = \lim_{x\to 0} -\abs{x} = 0\)
by previous result \(\lim_{x\to 0} f(x) = 0\).
From definition of \(f\) we see that \(f\) is continuous everywhere else hence \(f\) is continuous at every point on \(\R\).
